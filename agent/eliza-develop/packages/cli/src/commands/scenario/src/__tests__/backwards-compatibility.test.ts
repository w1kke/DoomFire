// File: packages/cli/src/commands/scenario/src/__tests__/backwards-compatibility.test.ts
// Tests ensuring perfect backwards compatibility with existing scenarios

import { describe, it, expect, beforeEach } from 'bun:test';
import { LocalEnvironmentProvider } from '../LocalEnvironmentProvider';
import { ScenarioSchema } from '../schema';
import type { Scenario } from '../schema';

describe('Backwards Compatibility', () => {
  const REAL_AGENT_ID = '54334a5c-cbd8-0f1f-a083-f5d48d8a7b82'; // Real agent from running server
  let mockRuntime: any;

  beforeEach(() => {
    mockRuntime = {
      useModel: async () => 'Mock runtime response',
      getSetting: (key: string) => {
        const settings: Record<string, string> = {
          OPENAI_API_KEY: 'mock-key',
          MODEL_PROVIDER: 'openai',
        };
        return settings[key] || null;
      },
    };
  });

  describe('Legacy Single-Turn Scenarios', () => {
    it('should execute original single-turn scenario without modifications', async () => {
      const legacyScenario: Scenario = {
        name: 'Legacy Customer Support Test',
        description: 'Original single-turn customer support scenario',
        environment: {
          type: 'local',
        },
        run: [
          {
            input: 'I need help with my account',
            evaluations: [
              {
                type: 'string_contains',
                value: 'account',
              },
              {
                type: 'llm_judge',
                prompt: 'Was the response helpful?',
                expected: 'yes',
              },
            ],
          },
        ],
        judgment: {
          strategy: 'all_pass',
        },
      };

      // Validate schema
      expect(() => ScenarioSchema.parse(legacyScenario)).not.toThrow();

      // Create provider and execute
      const provider = new LocalEnvironmentProvider(
        null, // Server object not needed for real askAgentViaApi calls
        REAL_AGENT_ID as any,
        mockRuntime,
        3000
      );

      await provider.setup(legacyScenario);
      const results = await provider.run(legacyScenario);

      expect(results).toHaveLength(1);
      expect(results[0].exitCode).toBe(0);
      expect(results[0].stdout).toContain('Agent response to: I need help with my account');
      expect(results[0].durationMs).toBeGreaterThan(0);

      // Should NOT have conversation metadata
      expect((results[0] as any).conversationMetadata).toBeUndefined();
    });

    it('should handle code execution scenarios unchanged', async () => {
      const codeScenario: Scenario = {
        name: 'Code Execution Test',
        description: 'Test bash script execution',
        environment: {
          type: 'local',
        },
        run: [
          {
            name: 'Echo test',
            lang: 'bash',
            code: "echo 'Hello from bash'",
            evaluations: [
              {
                type: 'string_contains',
                value: 'Hello from bash',
              },
              {
                type: 'execution_time',
                max_duration_ms: 5000,
              },
            ],
          },
        ],
        judgment: {
          strategy: 'all_pass',
        },
      };

      // Validate schema
      expect(() => ScenarioSchema.parse(codeScenario)).not.toThrow();

      const provider = new LocalEnvironmentProvider();
      await provider.setup(codeScenario);
      const results = await provider.run(codeScenario);

      expect(results).toHaveLength(1);
      expect(results[0].exitCode).toBe(0);
      expect(results[0].stdout).toContain('Hello from bash');
    });

    it('should support complex multi-step legacy scenarios', async () => {
      const complexScenario: Scenario = {
        name: 'Complex Multi-Step Legacy',
        description: 'Multiple steps with different types',
        plugins: [
          '@elizaos/plugin-bootstrap',
          {
            name: '@elizaos/plugin-custom',
            version: '1.0.0',
            config: { enabled: true },
            enabled: true,
          },
        ],
        environment: {
          type: 'local',
        },
        setup: {
          mocks: [
            {
              service: 'database',
              method: 'query',
              when: {
                input: { table: 'users' },
              },
              response: { count: 5 },
            },
          ],
          virtual_fs: {
            'test.txt': 'test content',
          },
        },
        run: [
          {
            name: 'Natural language step',
            input: 'Check the database for user count',
            evaluations: [
              {
                type: 'string_contains',
                value: 'database',
              },
            ],
          },
          {
            name: 'Code execution step',
            lang: 'python',
            code: "print(f'User count: {5}')",
            evaluations: [
              {
                type: 'string_contains',
                value: 'User count: 5',
              },
            ],
          },
          {
            name: 'File check step',
            lang: 'bash',
            code: 'ls test.txt',
            evaluations: [
              {
                type: 'file_exists',
                path: 'test.txt',
              },
            ],
          },
        ],
        judgment: {
          strategy: 'all_pass',
        },
      };

      // Validate schema
      expect(() => ScenarioSchema.parse(complexScenario)).not.toThrow();

      const provider = new LocalEnvironmentProvider(
        null, // Server object not needed for real askAgentViaApi calls
        REAL_AGENT_ID as any,
        mockRuntime,
        3000
      );

      await provider.setup(complexScenario);
      const results = await provider.run(complexScenario);

      expect(results).toHaveLength(3);

      // Natural language step
      expect(results[0].stdout).toContain('Agent response to: Check the database for user count');

      // Code execution steps should work
      expect(results[1].exitCode).toBe(0);
      expect(results[2].exitCode).toBe(0);
    });

    it('should handle all existing evaluation types', async () => {
      const evaluationScenario: Scenario = {
        name: 'All Evaluation Types Test',
        description: 'Test all existing evaluation types work unchanged',
        environment: {
          type: 'local',
        },
        run: [
          {
            input: 'Test all evaluations with trajectory data',
            evaluations: [
              {
                type: 'string_contains',
                value: 'trajectory',
              },
              {
                type: 'regex_match',
                pattern: '\\btrajectory\\b',
              },
              {
                type: 'trajectory_contains_action',
                action: 'SEARCH',
              },
              {
                type: 'llm_judge',
                prompt: 'Does this response mention testing?',
                expected: 'yes',
                temperature: 0.1,
                capabilities: ['analysis', 'reasoning'],
              },
              {
                type: 'execution_time',
                max_duration_ms: 30000,
                min_duration_ms: 100,
              },
            ],
          },
        ],
        judgment: {
          strategy: 'any_pass',
        },
      };

      // Validate schema
      expect(() => ScenarioSchema.parse(evaluationScenario)).not.toThrow();

      const provider = new LocalEnvironmentProvider(
        null, // Server object not needed for real askAgentViaApi calls
        REAL_AGENT_ID as any,
        mockRuntime,
        3000
      );

      await provider.setup(evaluationScenario);
      const results = await provider.run(evaluationScenario);

      expect(results).toHaveLength(1);
      expect(results[0].exitCode).toBe(0);
      expect(results[0].trajectory).toBeDefined();
    });
  });

  describe('Mixed Mode Scenarios', () => {
    it('should support mixing legacy and conversation steps in same scenario', async () => {
      const mixedScenario: Scenario = {
        name: 'Mixed Legacy and Conversation',
        description: 'Combine old and new step types',
        environment: {
          type: 'local',
        },
        run: [
          {
            name: 'Legacy single-turn step',
            input: 'This is a traditional step',
            evaluations: [
              {
                type: 'string_contains',
                value: 'traditional',
              },
            ],
          },
          {
            name: 'New conversation step',
            input: 'Start a conversation',
            conversation: {
              max_turns: 2,
              user_simulator: {
                persona: 'helpful user',
                objective: 'complete the conversation',
              },
            },
            evaluations: [
              {
                type: 'string_contains',
                value: 'conversation',
              },
            ],
          },
          {
            name: 'Another legacy step',
            lang: 'bash',
            code: "echo 'Back to legacy'",
            evaluations: [
              {
                type: 'string_contains',
                value: 'Back to legacy',
              },
            ],
          },
        ],
        judgment: {
          strategy: 'all_pass',
        },
      };

      // Validate schema
      expect(() => ScenarioSchema.parse(mixedScenario)).not.toThrow();

      const parsed = ScenarioSchema.parse(mixedScenario);

      // Verify step types
      expect(parsed.run[0].conversation).toBeUndefined(); // Legacy step
      expect(parsed.run[1].conversation).toBeDefined(); // Conversation step
      expect(parsed.run[2].conversation).toBeUndefined(); // Legacy step
      expect(parsed.run[2].lang).toBe('bash');

      const provider = new LocalEnvironmentProvider(
        null, // Server object not needed for real askAgentViaApi calls
        REAL_AGENT_ID as any,
        mockRuntime,
        3000
      );

      // Mock user simulator response
      mockRuntime.useModel = async (modelType: any, params: any) => {
        if (params.messages[0].content.includes('simulating a user')) {
          return 'Thank you, that completes our conversation!';
        }
        return 'Mock runtime response';
      };

      await provider.setup(mixedScenario);
      const results = await provider.run(mixedScenario);

      expect(results).toHaveLength(3);

      // First step: traditional
      expect(results[0].stdout).toContain('This is a traditional step');
      expect((results[0] as any).conversationMetadata).toBeUndefined();

      // Second step: conversation
      expect(results[1].stdout).toContain('Turn 1:');
      expect((results[1] as any).conversationMetadata).toBeDefined();
      expect((results[1] as any).conversationMetadata.turnCount).toBe(2);

      // Third step: legacy code
      expect(results[2].stdout).toContain('Back to legacy');
      expect((results[2] as any).conversationMetadata).toBeUndefined();
    });
  });

  describe('CLI Command Compatibility', () => {
    it('should maintain CLI command interface for legacy scenarios', () => {
      // Test that CLI commands work unchanged
      // This would typically be tested at a higher level, but we verify
      // that the scenario structure remains compatible

      const legacyScenarios = [
        {
          name: 'Simple Test',
          description: 'Basic test',
          environment: { type: 'local' as const },
          run: [{ input: 'test', evaluations: [] }],
          judgment: { strategy: 'all_pass' as const },
        },
        {
          name: 'Code Test',
          description: 'Code execution test',
          environment: { type: 'local' as const },
          run: [{ lang: 'python', code: "print('test')", evaluations: [] }],
          judgment: { strategy: 'any_pass' as const },
        },
      ];

      legacyScenarios.forEach((scenario, index) => {
        expect(() => ScenarioSchema.parse(scenario)).not.toThrow();

        const parsed = ScenarioSchema.parse(scenario);
        expect(parsed.name).toBe(scenario.name);
        expect(parsed.environment.type).toBe(scenario.environment.type);
        expect(parsed.judgment.strategy).toBe(scenario.judgment.strategy);

        // Ensure conversation field is optional and undefined for legacy scenarios
        parsed.run.forEach((step) => {
          expect(step.conversation).toBeUndefined();
        });
      });
    });

    it('should preserve all existing schema properties and defaults', () => {
      const minimalScenario = {
        name: 'Minimal',
        description: 'Test',
        environment: { type: 'local' as const },
        run: [{ evaluations: [] }],
        judgment: { strategy: 'all_pass' as const },
      };

      const parsed = ScenarioSchema.parse(minimalScenario);

      // Verify all expected properties exist
      expect(parsed.name).toBeDefined();
      expect(parsed.description).toBeDefined();
      expect(parsed.environment).toBeDefined();
      expect(parsed.run).toBeDefined();
      expect(parsed.judgment).toBeDefined();

      // Optional properties should be undefined for legacy scenarios
      expect(parsed.plugins).toBeUndefined();
      expect(parsed.setup).toBeUndefined();

      // Run steps should not have conversation config
      expect(parsed.run[0].conversation).toBeUndefined();
    });
  });

  describe('Error Handling Backwards Compatibility', () => {
    it('should provide same error messages for invalid legacy scenarios', () => {
      const invalidScenarios = [
        // Missing required fields
        {
          name: 'Invalid',
          // Missing description, environment, run, judgment
        },
        // Invalid judgment strategy
        {
          name: 'Invalid',
          description: 'Test',
          environment: { type: 'local' as const },
          run: [{ evaluations: [] }],
          judgment: { strategy: 'invalid_strategy' as any },
        },
        // Invalid environment type
        {
          name: 'Invalid',
          description: 'Test',
          environment: { type: 'invalid_env' as any },
          run: [{ evaluations: [] }],
          judgment: { strategy: 'all_pass' as const },
        },
      ];

      invalidScenarios.forEach((scenario) => {
        expect(() => ScenarioSchema.parse(scenario)).toThrow();
      });
    });

    it('should handle legacy scenario execution errors gracefully', async () => {
      const errorScenario: Scenario = {
        name: 'Error Test',
        description: 'Test error handling',
        environment: { type: 'local' },
        run: [
          {
            input: 'This should trigger an error',
            evaluations: [
              {
                type: 'string_contains',
                value: 'error',
              },
            ],
          },
        ],
        judgment: { strategy: 'all_pass' },
      };

      // Mock an API failure
      const originalModule = require('../runtime-factory');
      originalModule.askAgentViaApi = async () => {
        throw new Error('Simulated API failure');
      };

      const provider = new LocalEnvironmentProvider(
        null, // Server object not needed for real askAgentViaApi calls
        REAL_AGENT_ID as any,
        mockRuntime,
        3000
      );

      await provider.setup(errorScenario);

      try {
        await provider.run(errorScenario);
        expect(false).toBe(true); // Should not reach here
      } catch (error: any) {
        // Should handle errors the same way as before
        expect(error).toBeDefined();
        expect(typeof error.message).toBe('string');
      }
    });
  });

  describe('Performance Backwards Compatibility', () => {
    it('should maintain same performance characteristics for legacy scenarios', async () => {
      const performanceScenario: Scenario = {
        name: 'Performance Test',
        description: 'Test execution speed',
        environment: { type: 'local' },
        run: [
          {
            input: 'Quick response test',
            evaluations: [
              {
                type: 'execution_time',
                max_duration_ms: 5000,
              },
            ],
          },
        ],
        judgment: { strategy: 'all_pass' },
      };

      const provider = new LocalEnvironmentProvider(
        null, // Server object not needed for real askAgentViaApi calls
        REAL_AGENT_ID as any,
        mockRuntime,
        3000
      );

      const startTime = Date.now();

      await provider.setup(performanceScenario);
      const results = await provider.run(performanceScenario);

      const endTime = Date.now();
      const totalTime = endTime - startTime;

      expect(results).toHaveLength(1);
      expect(results[0].durationMs).toBeLessThan(5000);
      expect(totalTime).toBeLessThan(10000); // Total should be reasonable

      // Memory usage should be reasonable (no major leaks)
      // This is a basic check - in production, you'd use more sophisticated memory monitoring
      expect(process.memoryUsage().heapUsed).toBeLessThan(100 * 1024 * 1024); // 100MB limit
    });
  });
});
